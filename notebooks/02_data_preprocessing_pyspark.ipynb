{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T23:11:59.521517Z",
     "start_time": "2025-05-19T23:11:59.512398Z"
    },
    "id": "kmb0hLVS1_zs"
   },
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "import re"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T23:11:59.798634Z",
     "start_time": "2025-05-19T23:11:59.784591Z"
    },
    "id": "MmqfEQk_1_z2"
   },
   "source": [
    "# Initialize Spark Session with optimized settings\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Amazon Reviews Sentiment Analysis\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.python.worker.memory\", \"512m\") \\\n",
    "    .config(\"spark.python.worker.timeout\", \"600\") \\\n",
    "    .config(\"spark.network.timeout\", \"600s\") \\\n",
    "    .config(\"spark.executor.heartbeatInterval\", \"60s\") \\\n",
    "    .getOrCreate()"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T23:12:11.873905Z",
     "start_time": "2025-05-19T23:12:09.287971Z"
    },
    "id": "eC3qOfXu1_z2"
   },
   "source": [
    "# Load the data\n",
    "data_path = \"../data/raw/Data.json\"\n",
    "reviews_df = spark.read.json(data_path)"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T23:12:11.908940Z",
     "start_time": "2025-05-19T23:12:11.885899Z"
    },
    "id": "YMMLeF5i1_z5"
   },
   "source": [
    "# Create sentiment label based on overall rating\n",
    "reviews_df = reviews_df.withColumn(\n",
    "    \"sentiment\",\n",
    "    when(col(\"overall\") < 3, 0)  # 0 for negative\n",
    "    .when(col(\"overall\") == 3, 1)  # 1 for neutral\n",
    "    .otherwise(2)  # 2 for positive\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T23:12:11.998057Z",
     "start_time": "2025-05-19T23:12:11.935512Z"
    },
    "id": "A7aP0ca-1_z6"
   },
   "source": [
    "# Basic data cleaning\n",
    "reviews_df = reviews_df.filter(col(\"reviewText\").isNotNull())\n",
    "reviews_df = reviews_df.withColumn(\"reviewText\", regexp_replace(col(\"reviewText\"), \"[^a-zA-Z\\\\s]\", \" \"))\n",
    "reviews_df = reviews_df.withColumn(\"reviewText\", lower(col(\"reviewText\")))"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T23:12:12.138208Z",
     "start_time": "2025-05-19T23:12:12.030718Z"
    },
    "id": "-eZGZ_v_1_z6"
   },
   "source": [
    "# Split data into training, validation, and test sets (80%, 10%, 10%)\n",
    "train_df, temp_df = reviews_df.randomSplit([0.8, 0.2], seed=42)\n",
    "val_df, test_df = temp_df.randomSplit([0.5, 0.5], seed=42)"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T23:12:12.375488Z",
     "start_time": "2025-05-19T23:12:12.238967Z"
    },
    "id": "ILz5vqj21_z7"
   },
   "source": [
    "# Create ML Pipeline for text processing\n",
    "tokenizer = Tokenizer(inputCol=\"reviewText\", outputCol=\"words\")\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "cv = CountVectorizer(inputCol=\"filtered_words\", outputCol=\"raw_features\", minDF=2.0)\n",
    "idf = IDF(inputCol=\"raw_features\", outputCol=\"features\", minDocFreq=2)\n",
    "\n",
    "# Model training pipeline\n",
    "sentiment_indexer = StringIndexer(inputCol=\"sentiment\", outputCol=\"label\")\n",
    "\n",
    "# Create models with balanced class weights\n",
    "lr = LogisticRegression(maxIter=20, regParam=0.3, elasticNetParam=0, family=\"multinomial\")\n",
    "rf = RandomForestClassifier(numTrees=100, maxDepth=5, seed=42, minInstancesPerNode=1)\n",
    "nb = NaiveBayes(smoothing=1.0, modelType=\"multinomial\")"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T23:12:12.498290Z",
     "start_time": "2025-05-19T23:12:12.384488Z"
    },
    "id": "ak03A7NS1_z8"
   },
   "source": [
    "# Create pipelines for each model\n",
    "lr_pipeline = Pipeline(stages=[tokenizer, remover, cv, idf, sentiment_indexer, lr])\n",
    "rf_pipeline = Pipeline(stages=[tokenizer, remover, cv, idf, sentiment_indexer, rf])\n",
    "nb_pipeline = Pipeline(stages=[tokenizer, remover, cv, idf, sentiment_indexer, nb])"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T23:13:48.918591Z",
     "start_time": "2025-05-19T23:12:12.712177Z"
    },
    "id": "jJI9kLHO1_z-",
    "outputId": "6de65d44-b684-4f38-da4f-6b486b38d76c",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "# Train models\n",
    "print(\"Training Logistic Regression...\")\n",
    "lr_model = lr_pipeline.fit(train_df)\n",
    "\n",
    "print(\"Training Random Forest...\")\n",
    "rf_model = rf_pipeline.fit(train_df)\n",
    "\n",
    "print(\"Training Naive Bayes...\")\n",
    "nb_model = nb_pipeline.fit(train_df)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training Logistic Regression...\n",
      "Training Random Forest...\n",
      "Training Naive Bayes...\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T23:14:01.412021Z",
     "start_time": "2025-05-19T23:14:01.390407Z"
    },
    "id": "RMCW_W061_0B"
   },
   "source": [
    "# Function to evaluate model\n",
    "def evaluate_model(model, data, model_name):\n",
    "    predictions = model.transform(data)\n",
    "    evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "    accuracy = evaluator.evaluate(predictions)\n",
    "\n",
    "    # Calculate class distribution\n",
    "    class_dist = predictions.groupBy(\"label\").count()\n",
    "    print(f\"\\nClass distribution for {model_name}:\")\n",
    "    class_dist.show()\n",
    "\n",
    "    metrics = {\"accuracy\": accuracy}\n",
    "    print(f\"{model_name} Accuracy: {accuracy}\")\n",
    "\n",
    "    return metrics, predictions"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T23:14:11.796478Z",
     "start_time": "2025-05-19T23:14:05.784735Z"
    },
    "id": "tGxLXRgZ1_0C",
    "outputId": "1f9557e2-d901-4acf-ec71-54a3bb72220d",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "# Evaluate models on validation set\n",
    "lr_metrics, lr_preds = evaluate_model(lr_model, val_df, \"Logistic Regression\")\n",
    "rf_metrics, rf_preds = evaluate_model(rf_model, val_df, \"Random Forest\")\n",
    "nb_metrics, nb_preds = evaluate_model(nb_model, val_df, \"Naive Bayes\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Class distribution for Logistic Regression:\n",
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0|  880|\n",
      "|  1.0|   78|\n",
      "|  2.0|   47|\n",
      "+-----+-----+\n",
      "\n",
      "Logistic Regression Accuracy: 0.8706467661691543\n",
      "\n",
      "Class distribution for Random Forest:\n",
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0|  880|\n",
      "|  1.0|   78|\n",
      "|  2.0|   47|\n",
      "+-----+-----+\n",
      "\n",
      "Random Forest Accuracy: 0.8756218905472637\n",
      "\n",
      "Class distribution for Naive Bayes:\n",
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0|  880|\n",
      "|  1.0|   78|\n",
      "|  2.0|   47|\n",
      "+-----+-----+\n",
      "\n",
      "Naive Bayes Accuracy: 0.8119402985074626\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T23:16:30.263561Z",
     "start_time": "2025-05-19T23:16:30.240553Z"
    },
    "id": "nBGsO9VT1_0D",
    "outputId": "ff7fb3d4-a0fc-46f5-8b04-d4a1cce02396",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "# Select best model based on accuracy\n",
    "models = {\n",
    "    \"Logistic Regression\": (lr_metrics[\"accuracy\"], lr_model),\n",
    "    \"Random Forest\": (rf_metrics[\"accuracy\"], rf_model),\n",
    "    \"Naive Bayes\": (nb_metrics[\"accuracy\"], nb_model)\n",
    "}\n",
    "\n",
    "# Initialize variables to track the best model\n",
    "best_model_name = None\n",
    "best_model_accuracy = float('-inf')  # Start with negative infinity to ensure any accuracy is higher\n",
    "best_model = None\n",
    "\n",
    "# Iterate through models to find the one with highest accuracy\n",
    "for name, (accuracy, model) in models.items():\n",
    "    if accuracy > best_model_accuracy:\n",
    "        best_model_name = name\n",
    "        best_model_accuracy = accuracy\n",
    "        best_model = model\n",
    "\n",
    "# Print the result\n",
    "print(f\"Best model: {best_model_name} with accuracy: {best_model_accuracy}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best model: Random Forest with accuracy: 0.8756218905472637\n"
     ]
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T23:16:55.273234Z",
     "start_time": "2025-05-19T23:16:52.063206Z"
    },
    "id": "Q26gTNOt1_0E",
    "outputId": "361dc035-7116-4ccb-85a8-f63960e591a7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "source": [
    "# Evaluate best model on test set\n",
    "test_metrics, test_preds = evaluate_model(best_model, test_df, f\"Best Model ({best_model_name})\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Class distribution for Best Model (Random Forest):\n",
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|  0.0|  860|\n",
      "|  1.0|   78|\n",
      "|  2.0|   44|\n",
      "+-----+-----+\n",
      "\n",
      "Best Model (Random Forest) Accuracy: 0.8757637474541752\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T23:17:01.861586Z",
     "start_time": "2025-05-19T23:17:01.336444Z"
    },
    "id": "z8XBlMEw1_0E"
   },
   "source": [
    "# Save the best model\n",
    "best_model.write().overwrite().save(\"models/sentiment_model\")\n",
    "\n",
    "# Extract and save the TF-IDF model separately for use in streaming\n",
    "tfidf_stages = best_model.stages[0:4]  # Tokenizer, StopWordsRemover, CountVectorizer, IDF\n",
    "tfidf_pipeline = Pipeline(stages=tfidf_stages)\n",
    "tfidf_model = tfidf_pipeline.fit(train_df)\n",
    "tfidf_model.write().overwrite().save(\"models/tfidf_model\")"
   ],
   "outputs": [],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "yVke-jRb1_0O",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6a26e742-46e9-4023-d33e-70e43b8c8ad9"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model training and evaluation completed!\n"
     ]
    }
   ],
   "source": [
    "# Save processed data\n",
    "train_df.write.mode(\"overwrite\").parquet(\"data/processed/train_data.parquet\")\n",
    "val_df.write.mode(\"overwrite\").parquet(\"data/processed/val_data.parquet\")\n",
    "test_df.write.mode(\"overwrite\").parquet(\"data/processed/test_data.parquet\")\n",
    "\n",
    "print(\"Model training and evaluation completed!\")\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "spark.stop()"
   ],
   "metadata": {
    "id": "2Ey8BmsG3c6U"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "colab": {
   "provenance": [],
   "gpuType": "V28"
  },
  "accelerator": "TPU"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
