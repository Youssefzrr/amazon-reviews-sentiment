{
 "cells": [
  {
   "cell_type": "code",
   "id": "61f821e8-4ff1-42bf-86c6-56a65c9da0fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T19:28:49.105143Z",
     "start_time": "2025-05-19T19:28:47.949057Z"
    }
   },
   "source": [
    "import os\n",
    "import sys\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, StringIndexer\n",
    "from pyspark.ml.classification import (\n",
    "    LogisticRegression,\n",
    "    RandomForestClassifier,\n",
    "    NaiveBayes,\n",
    "    DecisionTreeClassifier\n",
    ")\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pymongo import MongoClient\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import StructType, StructField, StringType"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c5e9508-ce78-44dd-91bf-a5d932047a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===== Configuration pour exécution sur Windows =====\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "winutils_path = \"C:\\\\hadoop\"\n",
    "if os.path.exists(winutils_path):\n",
    "    os.environ[\"HADOOP_HOME\"] = winutils_path\n",
    "    os.environ[\"PATH\"] = f\"{os.environ['PATH']};{winutils_path}\\\\bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6267b488-8c5b-45da-9915-237e17b5cee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spark_session():\n",
    "    print(\"Initialisation de la session Spark...\")\n",
    "    try:\n",
    "        spark = SparkSession.builder \\\n",
    "            .appName(\"Train Sentiment Analysis Model\") \\\n",
    "            .config(\"spark.driver.memory\", \"2g\") \\\n",
    "            .config(\"spark.executor.memory\", \"2g\") \\\n",
    "            .config(\"spark.sql.shuffle.partitions\", \"2\") \\\n",
    "            .master(\"local[2]\") \\\n",
    "            .getOrCreate()\n",
    "        spark.sparkContext.setLogLevel(\"WARN\")\n",
    "        print(\"Session Spark initialisée avec succès\")\n",
    "        return spark\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'initialisation de Spark: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "536aebee-04ca-42e6-ae72-f60d0a89c328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_mongodb(spark):\n",
    "    print(\"Tentative de connexion à MongoDB...\")\n",
    "    try:\n",
    "        mongo_client = MongoClient(\"mongodb://root:example@localhost:27017\", serverSelectionTimeoutMS=5000)\n",
    "        mongo_client.server_info()\n",
    "        print(\"Connexion MongoDB établie avec succès\")\n",
    "        \n",
    "        db = mongo_client[\"big_data_project\"]\n",
    "        collection = db[\"preprocessed_reviews\"]\n",
    "        \n",
    "        print(\"Récupération des données depuis MongoDB...\")\n",
    "        raw_data = list(collection.find({}, {\"_id\": 0, \"cleanedReviewText\": 1, \"label\": 1}))\n",
    "        print(f\"Nombre de documents récupérés: {len(raw_data)}\")\n",
    "        \n",
    "        clean_data = []\n",
    "        for doc in raw_data:\n",
    "            try:\n",
    "                text = str(doc.get(\"cleanedReviewText\", \"\")).strip()\n",
    "                label = str(doc.get(\"label\", \"\")).lower()\n",
    "                if text and label:\n",
    "                    clean_data.append({\"cleanedReviewText\": text, \"label\": label})\n",
    "            except Exception as e:\n",
    "                print(f\"Erreur de traitement document: {str(e)}\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"Nombre de documents valides après nettoyage: {len(clean_data)}\")\n",
    "        \n",
    "        if not clean_data:\n",
    "            raise ValueError(\"Aucune donnée valide n'a été récupérée\")\n",
    "        \n",
    "        schema = StructType([\n",
    "            StructField(\"cleanedReviewText\", StringType(), nullable=False),\n",
    "            StructField(\"label\", StringType(), nullable=False)\n",
    "        ])\n",
    "        \n",
    "        df = spark.createDataFrame(clean_data, schema=schema).cache()\n",
    "        count = df.count()\n",
    "        print(f\"DataFrame créé avec {count} lignes\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du chargement des données MongoDB: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d049be5-d3d4-4a2e-997a-4601fdc3a78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df):\n",
    "    print(\"Partitionnement des données...\")\n",
    "    train_data, val_data, test_data = df.randomSplit([0.8, 0.1, 0.1], seed=42)\n",
    "    \n",
    "    print(f\"Données d'entraînement: {train_data.count()} exemples\")\n",
    "    print(f\"Données de validation: {val_data.count()} exemples\")\n",
    "    print(f\"Données de test: {test_data.count()} exemples\")\n",
    "    \n",
    "    return train_data, val_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2829a022-391b-47ad-8b00-6f914ce8a19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions_to_mongodb(predictions_df):\n",
    "    print(\"\\nSauvegarde des prédictions dans MongoDB...\")\n",
    "    try:\n",
    "        predictions_to_save = predictions_df.select(\n",
    "            F.col(\"cleanedReviewText\").alias(\"review_text\"),\n",
    "            F.col(\"label\").alias(\"actual_label\"),\n",
    "            F.col(\"prediction\").alias(\"predicted_label\"),\n",
    "            F.lit(datetime.now()).alias(\"prediction_timestamp\")\n",
    "        ).toPandas()\n",
    "\n",
    "        mongo_client = MongoClient(\"mongodb://root:example@localhost:27017\")\n",
    "        db = mongo_client[\"big_data_project\"]\n",
    "        collection = db[\"offline_predictions\"]\n",
    "        \n",
    "        if not predictions_to_save.empty:\n",
    "            collection.insert_many(predictions_to_save.to_dict('records'))\n",
    "            print(f\"{len(predictions_to_save)} prédictions sauvegardées\")\n",
    "        else:\n",
    "            print(\"Aucune prédiction à sauvegarder\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la sauvegarde : {str(e)}\")\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa3868ad-2a72-437b-a05e-e583cf19ce81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_metadata(best_model, model_name, test_accuracy):\n",
    "    print(\"\\nSauvegarde des métadonnées du modèle...\")\n",
    "    try:\n",
    "        params = {param.name: value for param, value in best_model.stages[-1].extractParamMap().items()}\n",
    "        \n",
    "        metadata = {\n",
    "            \"model_name\": model_name,\n",
    "            \"accuracy\": float(test_accuracy),\n",
    "            \"hyperparameters\": params,\n",
    "            \"training_date\": datetime.now(),\n",
    "            \"model_path\": \"models/best_model.pkl\",\n",
    "            \"test_size_percentage\": 10\n",
    "        }\n",
    "\n",
    "        mongo_client = MongoClient(\"mongodb://root:example@localhost:27017\")\n",
    "        db = mongo_client[\"big_data_project\"]\n",
    "        collection = db[\"model_metadata\"]\n",
    "        \n",
    "        collection.insert_one(metadata)\n",
    "        print(\"Métadonnées sauvegardées avec succès\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la sauvegarde : {str(e)}\")\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "235fa2f6-c24f-41c3-b63d-efcba2881889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_models(train_data, val_data, test_data):\n",
    "    print(\"Configuration du pipeline...\")\n",
    "    tokenizer = Tokenizer(inputCol=\"cleanedReviewText\", outputCol=\"words\")\n",
    "    hashing_tf = HashingTF(inputCol=\"words\", outputCol=\"features\")\n",
    "    label_indexer = StringIndexer(inputCol=\"label\", outputCol=\"indexedLabel\").fit(train_data)\n",
    "    \n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(featuresCol=\"features\", labelCol=\"indexedLabel\"),\n",
    "        \"Random Forest\": RandomForestClassifier(featuresCol=\"features\", labelCol=\"indexedLabel\"),\n",
    "        \"Naive Bayes\": NaiveBayes(featuresCol=\"features\", labelCol=\"indexedLabel\"),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(featuresCol=\"features\", labelCol=\"indexedLabel\")\n",
    "    }\n",
    "    \n",
    "    best_model = None\n",
    "    best_accuracy = 0\n",
    "    best_model_name = \"\"\n",
    "    \n",
    "    evaluator = MulticlassClassificationEvaluator(\n",
    "        labelCol=\"indexedLabel\", predictionCol=\"prediction\", metricName=\"accuracy\"\n",
    "    )\n",
    "    \n",
    "    for model_name, model in models.items():\n",
    "        print(f\"\\n=== Entraînement {model_name} ===\")\n",
    "        \n",
    "        # Configuration des hyperparamètres\n",
    "        param_grid = ParamGridBuilder()\n",
    "        if model_name == \"Logistic Regression\":\n",
    "            param_grid = param_grid \\\n",
    "                .addGrid(hashing_tf.numFeatures, [1000, 5000]) \\\n",
    "                .addGrid(model.regParam, [0.01, 0.1])\n",
    "        elif model_name == \"Random Forest\":\n",
    "            param_grid = param_grid \\\n",
    "                .addGrid(hashing_tf.numFeatures, [1000, 5000]) \\\n",
    "                .addGrid(model.numTrees, [10, 50]) \\\n",
    "                .addGrid(model.maxDepth, [5, 10])\n",
    "        elif model_name == \"Naive Bayes\":\n",
    "            param_grid = param_grid.addGrid(hashing_tf.numFeatures, [1000, 5000])\n",
    "        elif model_name == \"Decision Tree\":\n",
    "            param_grid = param_grid \\\n",
    "                .addGrid(hashing_tf.numFeatures, [1000, 5000]) \\\n",
    "                .addGrid(model.maxDepth, [5, 10])\n",
    "        \n",
    "        # Pipeline et validation croisée\n",
    "        pipeline = Pipeline(stages=[label_indexer, tokenizer, hashing_tf, model])\n",
    "        cross_validator = CrossValidator(\n",
    "            estimator=pipeline,\n",
    "            estimatorParamMaps=param_grid.build(),\n",
    "            evaluator=evaluator,\n",
    "            numFolds=3\n",
    "        )\n",
    "        \n",
    "        # Entraînement\n",
    "        cv_model = cross_validator.fit(train_data)\n",
    "        predictions = cv_model.transform(val_data)\n",
    "        accuracy = evaluator.evaluate(predictions)\n",
    "        print(f\"Précision validation: {accuracy:.4f}\")\n",
    "        \n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model = cv_model.bestModel\n",
    "            best_model_name = model_name\n",
    "    \n",
    "    # Évaluation finale\n",
    "    final_predictions = best_model.transform(test_data)\n",
    "    final_accuracy = evaluator.evaluate(final_predictions)\n",
    "    print(f\"\\n=== Meilleur modèle: {best_model_name} ===\")\n",
    "    print(f\"Précision test: {final_accuracy:.4f}\")\n",
    "    \n",
    "    # Sauvegardes MongoDB\n",
    "    save_predictions_to_mongodb(final_predictions)\n",
    "    save_model_metadata(best_model, best_model_name, final_accuracy)\n",
    "    \n",
    "    return best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb1d8c4b-ba69-444f-9a43-cee8bcf72e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    spark = create_spark_session()\n",
    "    try:\n",
    "        df = load_data_from_mongodb(spark)\n",
    "        if df is None:\n",
    "            print(\"ERREUR: Données non chargées\")\n",
    "            return\n",
    "        \n",
    "        print(\"\\nAperçu des données:\")\n",
    "        df.show(3, truncate=50)\n",
    "        \n",
    "        train_data, val_data, test_data = split_data(df)\n",
    "        trained_model = train_and_evaluate_models(train_data, val_data, test_data)\n",
    "        \n",
    "        if trained_model:\n",
    "            print(\"\\n=== Entraînement réussi ===\")\n",
    "        else:\n",
    "            print(\"\\nÉchec de l'entraînement\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"ERREUR: {str(e)}\")\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        print(\"\\nNettoyage des ressources...\")\n",
    "        spark.stop()\n",
    "        print(\"Session Spark fermée\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440a72c1-876b-4121-ac4a-98bd7a2ef4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialisation de la session Spark...\n",
      "Session Spark initialisée avec succès\n",
      "Tentative de connexion à MongoDB...\n",
      "Connexion MongoDB établie avec succès\n",
      "Récupération des données depuis MongoDB...\n",
      "Nombre de documents récupérés: 10257\n",
      "Nombre de documents valides après nettoyage: 10250\n",
      "DataFrame créé avec 10250 lignes\n",
      "\n",
      "Aperçu des données:\n",
      "+--------------------------------------------------+-------+\n",
      "|                                 cleanedReviewText|  label|\n",
      "+--------------------------------------------------+-------+\n",
      "|much write exactly supposed filter pop sound re...|positif|\n",
      "|product exactly quite affordablei realized doub...|positif|\n",
      "|primary job device block breath would otherwise...|positif|\n",
      "+--------------------------------------------------+-------+\n",
      "only showing top 3 rows\n",
      "\n",
      "Partitionnement des données...\n",
      "Données d'entraînement: 8253 exemples\n",
      "Données de validation: 1003 exemples\n",
      "Données de test: 994 exemples\n",
      "Configuration du pipeline...\n",
      "\n",
      "=== Entraînement Logistic Regression ===\n",
      "Précision validation: 0.8893\n",
      "\n",
      "=== Entraînement Random Forest ===\n",
      "Précision validation: 0.8893\n",
      "\n",
      "=== Entraînement Naive Bayes ===\n",
      "Précision validation: 0.8634\n",
      "\n",
      "=== Entraînement Decision Tree ===\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7399070a-7820-423f-8eed-ce6d4a505543",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7313166b-885c-4e33-b1b3-82ce630bef35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc485c0-8a08-46f3-8732-7a1395506c99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e1f442-7805-414e-be3b-dd5528be40cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d05cea6-1423-4400-9277-9b2e20c74f27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
